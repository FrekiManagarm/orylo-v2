# Story 4.1: Shadow Mode Validation & Enable New Code

---

## Status

**Draft**

---

## Story

**As a** product owner,  
**I want** valider que le nouveau code produit les mÃªmes dÃ©cisions que l'ancien,  
**so that** je peux migrer en production avec confiance.

---

## Acceptance Criteria

1. Shadow mode exÃ©cutÃ© pendant 1-2 semaines minimum
2. Agreement analysis : > 99% agreement entre ancien et nouveau
3. Divergences analysÃ©es et expliquÃ©es (amÃ©liorations intentionnelles)
4. Performance validation : nouveau code â‰¤ ancien code latency
5. DÃ©cision GO/NO-GO basÃ©e sur mÃ©triques objectives
6. Canary deployment : 1% â†’ 10% â†’ 50% â†’ 100% avec validation

**Integration Verification** :
- IV1: Automated tests valident agreement threshold
- IV2: Manual review des divergences > 1%
- IV3: Performance P95 < baseline + 100ms
- IV4: Error rate unchanged ou rÃ©duit

**Rollback Considerations** :
- Automatic rollback si metrics dÃ©gradent
- Manual rollback 24/7 disponible
- Rollback plan documentÃ© et testÃ©

---

## Tasks / Subtasks

- [ ] **Task 1: Run Shadow Mode** (AC: 1)
  - [ ] Enable `ENABLE_SHADOW_MODE=true`
  - [ ] Run for 1-2 weeks
  - [ ] Collect metrics

- [ ] **Task 2: Analyze Agreement** (AC: 2, 3)
  - [ ] Calculate agreement percentage
  - [ ] Analyze divergences
  - [ ] Document intentional improvements

- [ ] **Task 3: Validate Performance** (AC: 4)
  - [ ] Compare latency P50, P95, P99
  - [ ] Verify new code â‰¤ old code

- [ ] **Task 4: GO/NO-GO Decision** (AC: 5)
  - [ ] Review all metrics
  - [ ] Make decision based on objectives
  - [ ] Document decision

- [ ] **Task 5: Canary Deployment** (AC: 6)
  - [ ] Deploy to 1% traffic
  - [ ] Monitor for 48h
  - [ ] Increase to 10%, 50%, 100%

---

## Dev Notes

### Implementation: Where to Collect Metrics

**Metrics Collection Point** : Shadow mode comparison function in webhook handler

**File** : `lib/fraud-detection-v2/validation/shadow-mode.ts`

```typescript
interface ShadowModeMetrics {
  timestamp: Date;
  organizationId: string;
  paymentIntentId: string;
  
  // Decisions
  oldDecision: FraudDecision;
  newDecision: FraudDecision;
  decisionsMatch: boolean;
  
  // Latency (ms)
  oldLatency: number;
  newLatency: number;
  latencyDelta: number;
  
  // Scores
  oldScore: number;
  newScore: number;
  scoreDelta: number;
  
  // Factors
  oldFactorCount: number;
  newFactorCount: number;
  sharedFactors: string[];
  uniqueOldFactors: string[];
  uniqueNewFactors: string[];
}

// Metrics stored in DB
export async function logShadowModeMetrics(metrics: ShadowModeMetrics) {
  await db.insert(shadowModeMetrics).values(metrics);
}
```

**DB Schema** : New table `shadow_mode_metrics` (add to `lib/db/schemas/`)

```typescript
export const shadowModeMetrics = pgTable("shadow_mode_metrics", {
  id: text("id").primaryKey().$defaultFn(() => crypto.randomUUID()),
  organizationId: text("organization_id").notNull(),
  paymentIntentId: text("payment_intent_id").notNull(),
  
  oldDecision: text("old_decision").notNull(),
  newDecision: text("new_decision").notNull(),
  decisionsMatch: boolean("decisions_match").notNull(),
  
  oldLatency: integer("old_latency").notNull(),
  newLatency: integer("new_latency").notNull(),
  latencyDelta: integer("latency_delta").notNull(),
  
  oldScore: integer("old_score").notNull(),
  newScore: integer("new_score").notNull(),
  scoreDelta: integer("score_delta").notNull(),
  
  metadata: jsonb("metadata").$type<{
    oldFactorCount: number;
    newFactorCount: number;
    sharedFactors: string[];
    uniqueOldFactors: string[];
    uniqueNewFactors: string[];
  }>(),
  
  createdAt: timestamp("created_at").defaultNow().notNull(),
});
```

**Monitoring Dashboard** : Query this table for aggregate metrics

```sql
-- Agreement rate
SELECT 
  (COUNT(*) FILTER (WHERE decisions_match = true)::float / COUNT(*)) * 100 AS agreement_rate
FROM shadow_mode_metrics
WHERE created_at >= NOW() - INTERVAL '7 days';

-- Latency P95
SELECT 
  PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY new_latency) AS p95_latency
FROM shadow_mode_metrics
WHERE created_at >= NOW() - INTERVAL '7 days';
```

### Manual Analysis Process

**Who Analyzes** : Product Owner + Tech Lead (duo review)

**When** : Daily during shadow mode (15-30 min sessions)

**Tools** :
1. **Shadow Mode Dashboard** (new page in `/dashboard/shadow-mode`)
2. **Divergence Inspector** (drill-down view for mismatches)
3. **Logs** (structured logs with `logger.info()`)

**Analysis Workflow** :

**Step 1: Aggregate Metrics Review** (5 min)
- Check agreement rate (target > 99%)
- Check P50, P95, P99 latency (target < baseline + 100ms)
- Check error rate (should be unchanged)

**Step 2: Divergence Analysis** (10-20 min)
- Query divergences from `shadow_mode_metrics` table
- For each divergence:
  - Review `oldDecision` vs `newDecision`
  - Check `scoreDelta` and `uniqueFactors`
  - Classify as:
    - âœ… **Intentional Improvement** (new detector caught something)
    - âš ï¸ **Regression** (new code missed something)
    - ðŸ¤· **Edge Case** (ambiguous, needs discussion)

**Step 3: Documentation** (5 min)
- Document findings in `docs/shadow-mode-analysis.md`
- Create GitHub issues for regressions
- Update thresholds if needed

**Analysis Format** (Markdown document) :

```markdown
# Shadow Mode Analysis - 2026-01-15

## Metrics
- **Agreement Rate**: 99.3% (Target: > 99%) âœ…
- **P95 Latency**: 135ms (Baseline: 200ms, Target: < 300ms) âœ…
- **Total Transactions**: 1,247
- **Divergences**: 9 (0.7%)

## Divergence Breakdown

### Intentional Improvements (7)
1. **PI_abc123**: NEW detected card testing (5 cards in 3 min)
   - Old: ALLOW (missed pattern)
   - New: REVIEW (caught pattern)
   - âœ… Expected improvement

### Regressions (1)
1. **PI_xyz789**: NEW missed high-risk country
   - Old: REVIEW (GeographicDetector)
   - New: ALLOW (detector not registered?)
   - âš ï¸ BUG: Investigate detector registration

### Edge Cases (1)
1. **PI_def456**: Score delta = 5 points (boundary case)
   - Old: ALLOW (score 49)
   - New: REVIEW (score 51)
   - ðŸ¤· Threshold sensitivity - acceptable

## Action Items
- [ ] Fix: Register GeographicDetector properly
- [ ] Monitor: Track boundary cases (48-52 score range)
```

### Agreement Analysis

```typescript
const agreement = (identicalDecisions / totalDecisions) * 100;
// Target: > 99%
```

### Performance Validation

```typescript
const p95Latency = calculateP95(latencies);
// Target: < baseline + 100ms
```

---

## Testing

**Acceptance** :
- All 6 acceptance criteria met
- > 99% agreement
- Performance validated
- Canary deployment successful

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-08 | 1.0 | Story created from PRD | Sarah (PO) |

---
