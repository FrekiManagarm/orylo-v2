# Story 3.2: Implement AI Async Processing with Trigger.dev

---

## Status

**Draft**

---

## Story

**As a** system,  
**I want** générer les explications IA de façon asynchrone,  
**so that** la latence webhook est réduite de 50% (500-1000ms économisés).

---

## Acceptance Criteria

1. Trigger.dev setup et configuré (`TRIGGER_DEV_API_KEY` env var)
2. Job `generateFraudExplanationJob` créé dans `lib/jobs/ai-explanation.job.ts`
3. Fallback explanation immédiate (formatFallbackExplanation)
4. Enqueue job après DB save dans `handlePaymentIntentCreated()`
5. Webhook job met à jour `fraudDetections.aiExplanation` + `aiGeneratedAt`
6. Retry automatique (3 tentatives) avec exponential backoff
7. Priority queue : HIGH pour BLOCK/REVIEW, NORMAL pour ALLOW
8. **Performance** : Webhook latency réduite de 500-1000ms

**Integration Verification** :
- IV1: Fallback explanation testée (OpenAI down scenario)
- IV2: Job execution monitored (success rate, latency)
- IV3: UI dashboard affiche explanation dès disponible (pas de freeze)
- IV4: Graceful degradation si Trigger.dev down (fallback sync)

**Rollback Considerations** :
- Feature flag `USE_ASYNC_AI` pour activer/désactiver
- Circuit breaker si Trigger.dev unhealthy
- Fallback vers génération synchrone si queue saturée

---

## Tasks / Subtasks

- [ ] **Task 1: Setup Trigger.dev** (AC: 1)
  - [ ] Run `bun add @trigger.dev/sdk`
  - [ ] Run `bunx trigger.dev@latest init`
  - [ ] Configure `TRIGGER_API_KEY` env var
  - [ ] Create Trigger.dev client

- [ ] **Task 2: Create AI Explanation Job** (AC: 2, 5, 6, 7)
  - [ ] Create `lib/jobs/ai-explanation.job.ts`
  - [ ] Implement job logic (call OpenAI, update DB)
  - [ ] Add retry logic (3 attempts, exponential backoff)
  - [ ] Add priority queue logic

- [ ] **Task 3: Create Fallback Explanation** (AC: 3)
  - [ ] Create `formatFallbackExplanation()` function
  - [ ] Return simple explanation immediately

- [ ] **Task 4: Integrate into Webhook** (AC: 4)
  - [ ] Update `handlePaymentIntentCreated()`
  - [ ] Enqueue job after DB save
  - [ ] Return fallback explanation immediately

- [ ] **Task 5: Performance Testing** (AC: 8)
  - [ ] Measure webhook latency before/after
  - [ ] Verify 500-1000ms reduction

---

## Dev Notes

### Trigger.dev Setup & Configuration

**CRITICAL** : Trigger.dev requires specific project structure and configuration files.

**Step 1: Install Trigger.dev SDK**
```bash
bun add @trigger.dev/sdk
bunx trigger.dev@latest init
```

**Step 2: Configuration Files Created** (by `trigger.dev init`)

1. **`trigger.config.ts`** (root of project) :
```typescript
import { defineConfig } from "@trigger.dev/sdk/v3";

export default defineConfig({
  project: "proj_YOUR_PROJECT_ID", // From Trigger.dev dashboard
  runtime: "node",
  logLevel: "info",
  retries: {
    enabledInDev: true,
    default: {
      maxAttempts: 3,
      minTimeoutInMs: 1000,
      maxTimeoutInMs: 10000,
      factor: 2,
      randomize: true,
    },
  },
});
```

2. **`trigger/index.ts`** (Trigger.dev client instance) :
```typescript
import { TriggerClient } from "@trigger.dev/sdk";

export const client = new TriggerClient({
  id: "orylo-v2",
  apiKey: process.env.TRIGGER_API_KEY,
  apiUrl: process.env.TRIGGER_API_URL,
});
```

3. **Environment Variables** (`.env`) :
```env
TRIGGER_API_KEY=tr_dev_YOUR_DEV_KEY  # From Trigger.dev dashboard
TRIGGER_API_URL=https://api.trigger.dev  # Default
```

**Step 3: Vercel Deployment Integration**

Trigger.dev integrates with Vercel via:
- **Build step** : `bunx trigger.dev@latest deploy` in Vercel build command
- **Runtime** : Jobs run on Trigger.dev infrastructure (NOT Vercel serverless)
- **Webhook** : Vercel webhook triggers Trigger.dev jobs via event emitters

**Vercel Configuration** (`vercel.json`) :
```json
{
  "buildCommand": "bun run build && bunx trigger.dev@latest deploy",
  "env": {
    "TRIGGER_API_KEY": "@trigger-api-key",  // Add to Vercel env vars
    "TRIGGER_API_URL": "https://api.trigger.dev"
  }
}
```

**IMPORTANT** : Trigger.dev jobs are **NOT** serverless functions. They run on Trigger.dev's infrastructure, which bypasses Vercel's 10-second timeout limit.

### Fallback Explanation Implementation

**Function Signature** :
```typescript
function formatFallbackExplanation(
  decision: FraudDecision,
  factors: FraudFactor[]
): string;
```

**Implementation** (`lib/fraud-detection-v2/ai/fallback-explanation.ts`) :
```typescript
export function formatFallbackExplanation(
  decision: FraudDecision,
  factors: FraudFactor[]
): string {
  const decisionText = {
    BLOCK: "Cette transaction a été bloquée",
    REVIEW: "Cette transaction nécessite une vérification manuelle",
    ALLOW: "Cette transaction a été approuvée",
  }[decision];

  if (factors.length === 0) {
    return `${decisionText} sans facteurs de risque détectés.`;
  }

  // Sort factors by weight (highest first)
  const sortedFactors = factors
    .sort((a, b) => Math.abs(b.weight) - Math.abs(a.weight))
    .slice(0, 3); // Top 3 factors

  const factorDescriptions = sortedFactors
    .map((f, i) => `${i + 1}. ${f.description}`)
    .join('\n');

  return `${decisionText} pour les raisons suivantes:\n\n${factorDescriptions}\n\nℹ️ Explication détaillée en cours de génération...`;
}
```

**Output Format** (matches UI expectations) :
- Plain text with line breaks (`\n`)
- Numbered list of top 3 factors
- Decision summary at top
- "En cours de génération..." message at bottom

### Job Example

```typescript
// lib/jobs/ai-explanation.job.ts
import { client } from "@/trigger";

export const generateFraudExplanationJob = client.defineJob({
  id: "generate-fraud-explanation",
  name: "Generate Fraud Explanation",
  version: "1.0.0",
  trigger: eventTrigger({
    name: "fraud.detection.created",
  }),
  run: async (payload, io, ctx) => {
    const { detectionId } = payload;
    
    // Generate AI explanation
    const explanation = await io.openai.chat.completions.create("generate-explanation", {
      model: "gpt-4o-mini",
      messages: [/* ... */],
    });
    
    // Update DB
    await io.runTask("update-db", async () => {
      await db.update(fraudDetections)
        .set({ 
          aiExplanation: explanation.choices[0].message.content,
          aiGeneratedAt: new Date(),
        })
        .where(eq(fraudDetections.id, detectionId));
    });
  },
});
```

### Priority Queue Implementation

```typescript
// High priority for BLOCK/REVIEW
const priority = decision === "BLOCK" || decision === "REVIEW" 
  ? "high" 
  : "normal";

await client.sendEvent({
  name: "fraud.detection.created",
  payload: { detectionId },
  options: { priority }, // Trigger.dev priority
});
```

---

## Testing

**Acceptance** :
- All 8 acceptance criteria met
- Webhook latency reduced by 500-1000ms
- Fallback works correctly
- Job execution successful

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-01-08 | 1.0 | Story created from PRD | Sarah (PO) |

---
